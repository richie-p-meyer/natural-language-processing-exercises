{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e8a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa67537",
   "metadata": {},
   "source": [
    "Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:  \n",
    "  \n",
    "Lowercase everything  \n",
    "Normalize unicode characters  \n",
    "Replace anything that is not a letter, number, whitespace or a single quote.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b0df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    string = string.lower()\n",
    "    string = unicodedata.normalize('NFKD', string).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    string = re.sub(\"[^A-Za-z0-9\\s']\",'',string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68342fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = 'i have having had so much swim swam swimming swum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2280852d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i have having had so much swim swam swimming swum'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_clean(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04734b83",
   "metadata": {},
   "source": [
    "Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bcca66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    return tokenizer.tokenize(string,return_str=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bee60a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i have having had so much swim swam swimming swum'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc47f3",
   "metadata": {},
   "source": [
    "Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91c6c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    return [ps.stem(w) for w in string.split()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec2b4afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'have', 'have', 'had', 'so', 'much', 'swim', 'swam', 'swim', 'swum']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35042d9a",
   "metadata": {},
   "source": [
    "Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43a379ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    return [wnl.lemmatize(w) for w in string.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a4af366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'have',\n",
       " 'having',\n",
       " 'had',\n",
       " 'so',\n",
       " 'much',\n",
       " 'swim',\n",
       " 'swam',\n",
       " 'swimming',\n",
       " 'swum']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9709d6",
   "metadata": {},
   "source": [
    "Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00e9b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string,extra_words=None,exclude_words=None):\n",
    "    stopword_list = stopwords.words('english')\n",
    "    if extra_words != None:\n",
    "        stopword_list.remove(extra_words)\n",
    "    if exclude_words != None:  \n",
    "        stopword_list.append(exclude_words)\n",
    "    words = string.split()\n",
    "    return [w for w in words if w not in stopword_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d508110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['much', 'swim', 'swam', 'swimming', 'swum']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef53cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
